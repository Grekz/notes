{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(0, 5001,(1000,20))\n",
    "\n",
    "# print the shape of X\n",
    "print(X.shape)\n",
    "# print(X.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1464.13897441,  1455.92430057,  1449.75306117,  1471.65977158,\n",
       "        1459.76021423,  1474.00378714,  1471.04896538,  1423.28470576,\n",
       "        1462.55498782,  1465.55828467,  1445.35326605,  1412.33942839,\n",
       "        1426.7290786 ,  1480.66688415,  1405.61316042,  1458.67827043,\n",
       "        1404.80956678,  1418.98588712,  1430.77232221,  1457.53752249])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = X.mean(axis=0)\n",
    "\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = X.std(axis=0)\n",
    "# std_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols.shape)\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print(std_cols.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean normalize X\n",
    "X_norm = (X - ave_cols) / std_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.24161847 -0.70816319  1.13682878 ...,  0.14456169  0.73841029\n",
      "  -1.07792216]\n",
      " [ 1.76137788 -0.18341063 -0.08820744 ..., -0.3128072  -0.83486588\n",
      "  -1.3180532 ]\n",
      " [-0.96855423 -0.486311   -0.50138125 ..., -1.72578813 -0.51755474\n",
      "   1.46883903]\n",
      " ..., \n",
      " [-0.98153114  0.89700268 -0.68968918 ..., -1.48054256 -0.58604922\n",
      "   1.35083178]\n",
      " [ 0.71844409  0.89700268 -1.32496978 ...,  0.20164471  1.17383945\n",
      "   1.17107654]\n",
      " [ 0.36192056 -1.54611885  1.00232311 ..., -1.08941816  1.24163501\n",
      "   1.29663077]]\n",
      "-1.72600327615\n",
      "1.72554010522\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print(X_norm)\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(X_norm.min(axis=0).mean())\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print(X_norm.max(axis=0).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 1, 3, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[708 914 897 866 441 475 742 458 191 911 704 401 396 124 402 807 638 484\n",
      " 846 820 784 959 466 168 238 355 760 844 199 617 459 194 680 995 852 993\n",
      " 339 786 229 127 756 980 557  68 171  56 640 683 203 114 328 772 824 856\n",
      "  69 326 878 371 869 397 568 479 850 367 663 564 343 209 306 560 118 413\n",
      " 357 706 439 917 295 513 779 282  53 444 818 629 228  63 279 428 935 664\n",
      " 937 797 576 597  78 387 985 595 190 379 467 490   5 348  50 758 635 336\n",
      " 247 943 263 879 593 176 422 836 552 448 902  37 447 604 798 642 109 429\n",
      " 785 960 277 918 667 421 987 752 991 254 928 829 122 112 981 684 666 408\n",
      " 437 469 884 767 867  92  46  60 240 927 519 913 358 436 780 887 736 854\n",
      " 771 243 514 543 669 308 579 639 320 827 674 720 572 492 802 810 155 472\n",
      " 309 151 613 162 892 208 516 530 245  90 724 732 237 131 230 573 972 538\n",
      " 755 283  89 842 747 495 463 182 172 491 966 873 983 610 603   8 832 370\n",
      " 499 839 915 658 111 391 236 145 623 498 350 404 278 932 356 535 349 409\n",
      "  42 721 594 311 753 707 733 260 940 115 731 315  83 435 701 372 382 218\n",
      " 126  88 125 734   9 489 682 301 419 280  58 596 340 482 488 183 648 226\n",
      " 452 189 334 975 523 291 298 185 257 224 717 267 909  30 433  49 455 865\n",
      " 700 906 369 546  73 192 605 158 426 184 647 921  26 956 376 341 304 485\n",
      " 794 544 215 855 169 743 299 653 120 627 969 845 681 144 699 252 248 712\n",
      " 989 164 202  18   1  84 808 545 412 833 584 360  65  47 687 977 104 424\n",
      " 246 241 823  35 768 565 157 672 730 506 142 518  85 420 907 611 710 505\n",
      " 389 947 933 529 922 831 862 373  29 745 934 449 566 232 912 266  20 524\n",
      " 592 570 153  98 342 287 690 838 787 353 121 477 143 300 550 963  52  61\n",
      " 520 624 716  77 503 481  96  91 507 792 757  17 548 702 415 903 901 547\n",
      " 601  76 294 931 882 908 886 195 999 692 434 476 540 152 101 665 693 213\n",
      " 616 925 738 900 526 438 534 948 265  57 352  13   0 809 805 923 332 554\n",
      "  25 851 330 106 769  15 941 113 979 337 150 305 204 722 108 837 290 525\n",
      " 703  12 137 894 830 331 179 871 998 186 375 781 924 962 656 116 868 944\n",
      " 515 955 414 896 735 615 790  27 949 676 385 366 553 200 510 608 502 273\n",
      " 133 216 431 344 244 967 456 393  59 698 528 586 117 223  71 625 231 916\n",
      " 834  48 822 217  45 843 840 929 888  19 946 657 880 222 793 362 395 688\n",
      " 697 451 541 575 729 905 926 651 749  72 110 580 562 992  38 139 317 327\n",
      " 973 293 411 407 709 650 147 750 410 770 442  41 630 942 536 660 976 501\n",
      " 394 249 819 590 146  70 527 446 494 474 954 588 950 312 180 322 148 166\n",
      "  87 619 417 857 177 128 333 188 132 380 813 255 156 776 123  80 904 165\n",
      " 271 853 531 100 581 418 971 272 159 253 872 645 711 364 637 762  67  66\n",
      " 450 365 996 539 694 405 997 198 423 961 825 105 175 149 583 881 812 652\n",
      " 686 990 858 532 678 197 891 626  16 654 607 877 569 799 285 835 952 746\n",
      " 318 765 585 325 689  81 751 559 744 863 621 849 388 310 504 775 634 377\n",
      "  10 945 392 938 533 140 130 483 723 427 874 563 696  44  86   2 497 861\n",
      " 470  11  22 806 363 826 284 316 384 512 136 571 461 556 134 754 262 895\n",
      " 883 390 705 511 542 600 234 759  40 636 796 517 261 313 984 795 453 201\n",
      "  24 558 675 778 919 555 211 671 351 549 828 425 212 655 777 403 480 994\n",
      " 691 714 859 323 930 864 464 612 773 478  97 715 430 432 953 783 522 205\n",
      " 161 374 561 207 804 958  36 643  74 939 270 582 814 251 468 791 486 662\n",
      " 679 951 399 957 661 496 606 899  93 673 471 587  23 737 235 631 726 167\n",
      " 368 346 618 381 848 163 936 170 276 500 847 303 258   6 964 406 591 239\n",
      " 633 988 982  82 321 181 400 602 782 875  43 107 473  31 196 354 646 174\n",
      " 338 598  34 219 281 968 324 890 443 233 242  51 135 670 727 537  95 103\n",
      " 740 659 728 898 803 173 154 141 725 641 910 893 297 335 577  28 965 221\n",
      " 329 885 876 288 815 677 628 508 227 462 521 764 578 445 302 187 259 741\n",
      " 763  64 574 454 986 361  33 788 789 970  75 210 817  32 774 457 256 440\n",
      " 206 766 250 713 622 649 685  99 620 269 264 761 644 841 119 870 889 460\n",
      " 632 220 493 695 178 609 378 129  21 589 487 668  62 974 398  54 599 386\n",
      " 383  55 816 314 268  94 551 214  14 801 920 860   3 193   4  79 614 307\n",
      " 296 416 319 821   7 345 978 292 567  39 465 225 275 718 347 509 359 138\n",
      " 719 102 748 800 739 811 160 289 286 274]\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices = np.random.permutation(X_norm.shape[0])\n",
    "print(row_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "row_indices_len = len(row_indices)\n",
    "\n",
    "# Create a Training Set\n",
    "X_train = row_indices[:int(row_indices_len * 0.6)]\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = row_indices[int(row_indices_len * 0.6):int(row_indices_len * 0.8)]\n",
    "\n",
    "# Create a Test Set\n",
    "X_test = row_indices[int(row_indices_len * 0.8):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[708 914 897 866 441 475 742 458 191 911 704 401 396 124 402 807 638 484\n",
      " 846 820 784 959 466 168 238 355 760 844 199 617 459 194 680 995 852 993\n",
      " 339 786 229 127 756 980 557  68 171  56 640 683 203 114 328 772 824 856\n",
      "  69 326 878 371 869 397 568 479 850 367 663 564 343 209 306 560 118 413\n",
      " 357 706 439 917 295 513 779 282  53 444 818 629 228  63 279 428 935 664\n",
      " 937 797 576 597  78 387 985 595 190 379 467 490   5 348  50 758 635 336\n",
      " 247 943 263 879 593 176 422 836 552 448 902  37 447 604 798 642 109 429\n",
      " 785 960 277 918 667 421 987 752 991 254 928 829 122 112 981 684 666 408\n",
      " 437 469 884 767 867  92  46  60 240 927 519 913 358 436 780 887 736 854\n",
      " 771 243 514 543 669 308 579 639 320 827 674 720 572 492 802 810 155 472\n",
      " 309 151 613 162 892 208 516 530 245  90 724 732 237 131 230 573 972 538\n",
      " 755 283  89 842 747 495 463 182 172 491 966 873 983 610 603   8 832 370\n",
      " 499 839 915 658 111 391 236 145 623 498 350 404 278 932 356 535 349 409\n",
      "  42 721 594 311 753 707 733 260 940 115 731 315  83 435 701 372 382 218\n",
      " 126  88 125 734   9 489 682 301 419 280  58 596 340 482 488 183 648 226\n",
      " 452 189 334 975 523 291 298 185 257 224 717 267 909  30 433  49 455 865\n",
      " 700 906 369 546  73 192 605 158 426 184 647 921  26 956 376 341 304 485\n",
      " 794 544 215 855 169 743 299 653 120 627 969 845 681 144 699 252 248 712\n",
      " 989 164 202  18   1  84 808 545 412 833 584 360  65  47 687 977 104 424\n",
      " 246 241 823  35 768 565 157 672 730 506 142 518  85 420 907 611 710 505\n",
      " 389 947 933 529 922 831 862 373  29 745 934 449 566 232 912 266  20 524\n",
      " 592 570 153  98 342 287 690 838 787 353 121 477 143 300 550 963  52  61\n",
      " 520 624 716  77 503 481  96  91 507 792 757  17 548 702 415 903 901 547\n",
      " 601  76 294 931 882 908 886 195 999 692 434 476 540 152 101 665 693 213\n",
      " 616 925 738 900 526 438 534 948 265  57 352  13   0 809 805 923 332 554\n",
      "  25 851 330 106 769  15 941 113 979 337 150 305 204 722 108 837 290 525\n",
      " 703  12 137 894 830 331 179 871 998 186 375 781 924 962 656 116 868 944\n",
      " 515 955 414 896 735 615 790  27 949 676 385 366 553 200 510 608 502 273\n",
      " 133 216 431 344 244 967 456 393  59 698 528 586 117 223  71 625 231 916\n",
      " 834  48 822 217  45 843 840 929 888  19 946 657 880 222 793 362 395 688\n",
      " 697 451 541 575 729 905 926 651 749  72 110 580 562 992  38 139 317 327\n",
      " 973 293 411 407 709 650 147 750 410 770 442  41 630 942 536 660 976 501\n",
      " 394 249 819 590 146  70 527 446 494 474 954 588 950 312 180 322 148 166\n",
      "  87 619 417 857 177 128]\n",
      "[333 188 132 380 813 255 156 776 123  80 904 165 271 853 531 100 581 418\n",
      " 971 272 159 253 872 645 711 364 637 762  67  66 450 365 996 539 694 405\n",
      " 997 198 423 961 825 105 175 149 583 881 812 652 686 990 858 532 678 197\n",
      " 891 626  16 654 607 877 569 799 285 835 952 746 318 765 585 325 689  81\n",
      " 751 559 744 863 621 849 388 310 504 775 634 377  10 945 392 938 533 140\n",
      " 130 483 723 427 874 563 696  44  86   2 497 861 470  11  22 806 363 826\n",
      " 284 316 384 512 136 571 461 556 134 754 262 895 883 390 705 511 542 600\n",
      " 234 759  40 636 796 517 261 313 984 795 453 201  24 558 675 778 919 555\n",
      " 211 671 351 549 828 425 212 655 777 403 480 994 691 714 859 323 930 864\n",
      " 464 612 773 478  97 715 430 432 953 783 522 205 161 374 561 207 804 958\n",
      "  36 643  74 939 270 582 814 251 468 791 486 662 679 951 399 957 661 496\n",
      " 606 899]\n",
      "[ 93 673 471 587  23 737 235 631 726 167 368 346 618 381 848 163 936 170\n",
      " 276 500 847 303 258   6 964 406 591 239 633 988 982  82 321 181 400 602\n",
      " 782 875  43 107 473  31 196 354 646 174 338 598  34 219 281 968 324 890\n",
      " 443 233 242  51 135 670 727 537  95 103 740 659 728 898 803 173 154 141\n",
      " 725 641 910 893 297 335 577  28 965 221 329 885 876 288 815 677 628 508\n",
      " 227 462 521 764 578 445 302 187 259 741 763  64 574 454 986 361  33 788\n",
      " 789 970  75 210 817  32 774 457 256 440 206 766 250 713 622 649 685  99\n",
      " 620 269 264 761 644 841 119 870 889 460 632 220 493 695 178 609 378 129\n",
      "  21 589 487 668  62 974 398  54 599 386 383  55 816 314 268  94 551 214\n",
      "  14 801 920 860   3 193   4  79 614 307 296 416 319 821   7 345 978 292\n",
      " 567  39 465 225 275 718 347 509 359 138 719 102 748 800 739 811 160 289\n",
      " 286 274]\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print(X_train)\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "print(X_crossVal)\n",
    "\n",
    "# Print the shape of X_test\n",
    "print(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
